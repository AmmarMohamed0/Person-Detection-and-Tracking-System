{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50a58d2-dfff-4be8-b128-a2acc6e6d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ASUS/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-2-10 Python-3.11.5 torch-2.2.0+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "count = set() # to store the ID of a person \n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "cap=cv2.VideoCapture(\"C:/Users/ASUS/Downloads/project/cctv.mp4\")\n",
    "\n",
    "def print_mouse_position(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        position = [x, y]\n",
    "        print(position)\n",
    "        \n",
    "cv2.namedWindow('FRAME')\n",
    "#cv2.setMouseCallback('FRAME', position) # to identify area by mouse event\n",
    "\n",
    "tracker = Tracker()\n",
    "area = [(377,315),(429,373),(535,339),(500,296)]\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    frame=cv2.resize(frame, (1020, 500))\n",
    "    cv2.polylines(frame,[np.array(area,np.int32)] ,True, (0, 255, 0), 2)\n",
    "    results = model(frame)\n",
    "    #frame = np.squeeze(results.render())\n",
    "    points = [] # to store the coordinates of a person\n",
    "    for index , row in results.pandas().xyxy[0].iterrows():\n",
    "        x1, y1, x2, y2 = map(int, [row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n",
    "        n=(row['name'])\n",
    "        if 'person' in n:\n",
    "            points.append([x1, y1, x2, y2]) \n",
    "            #cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "            #cv2.putText(frame, str(n), (x1, y1), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "\n",
    "    boxes_id = tracker.update(points) # make a unique ID for each person  \n",
    "    #print(boxes_id)\n",
    "    for box_id in boxes_id:\n",
    "        x, y, w, h, idd = box_id\n",
    "        cv2.rectangle(frame,(x, y), (w, h), (255, 0, 255), 2)\n",
    "        cv2.putText(frame,str(idd),(x,y),cv2.FONT_HERSHEY_PLAIN,3,(255,0,0),2)\n",
    "        if cv2.pointPolygonTest(np.array(area,np.int32), (w,h), False)>=0:\n",
    "            count.add(idd)\n",
    "    #print(c) \n",
    "    sum = len(count)\n",
    "    cv2.putText(frame,'number of persons is ='+str(sum), (50,65), cv2.FONT_HERSHEY_PLAIN, 3, (0,0,0),4)\n",
    "    \n",
    "    cv2.imshow('FRAME',frame)\n",
    "    if cv2.waitKey(15)&0xFF==27: # because frame rate for that video 15 frames/second\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25af7d9-38c6-42fd-b4c5-58b31f53a883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
